{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jason 2 Two Dimensional Fourier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "import csv\n",
    "import Jason2_py as Jason2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Plotting Functions\n",
    "import holoviews as hv\n",
    "import cartopy.crs as ccrs\n",
    "import plot_funcs as pf\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jason2_py\n",
    "\n",
    "The Python package written for this project, `Jason2_py`, can be found at https://github.com/theo-yang/jason2. The package contains the following modules:\n",
    "\n",
    "- `Jason2_py.download.py`: tools for downloading and reading Jason-2 ssha data directly from the online repository, as well as functions for reading netcdf files from Copernicus datasets. ECCOv4 datasets can be read using [ecco_v4_py](https://ecco-v4-python-tutorial.readthedocs.io/)\n",
    "\n",
    "- `Jason2_py.preprocess.py`: tools for removing ssha datasets based on NaN and distance thresholds.\n",
    "\n",
    "- `find_2D_power_spectrum.py`: function for calculating the Hann-windowed two dimensional Fourier transform of ssha data.\n",
    "\n",
    "- `Jason2_py.model.py`: tools for modeling the two-dimensional Fourier transform of ssha, as discussed [here](#Models-for-Two-Dimensional-Fourier-Transform)\n",
    "\n",
    "See full dosctrings using `?` operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "The following analysis uses datasets from the following sources:\n",
    "- [Jason-2](https://data.nodc.noaa.gov/jason2/gdr/gdr_ssha) for sea-surface height anomaly\n",
    "- [ECCOv4](https://www.ecco-group.org/home.cgi) for stratification climatology\n",
    "- [Copernicus](https://cds.climate.copernicus.eu/cdsapp#!/dataset/satellite-sea-level-global?tab=overview) for sea surface currents\n",
    "\n",
    "Now let's download the data for this demonstration (*you can also just [download from saved data files](#dwnld)*):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jason-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get existing cycles:\n",
    "f = open(\"cycles.txt\", \"r\")\n",
    "cycles = [line.strip()[1:4] for line in f]\n",
    "\n",
    "# define reference cycle\n",
    "ref_cycle = '100'\n",
    "\n",
    "# target start point and track length\n",
    "starts = [[14.5,-167],\n",
    "          [13.5,-164.5],\n",
    "          [12.5,-162],\n",
    "          [10.5,-160]]\n",
    "track_length = 1000\n",
    "direction = 'N'\n",
    "\n",
    "# download and read ssha data for ascending tracks South of Hawaiian Ridge\n",
    "Hawaii_SA_raw = Jason2.nested_dict()\n",
    "for track in range(4):\n",
    "   \n",
    "    # define start and reference file:\n",
    "    start = starts[track]\n",
    "    reference_file = Jason2.download.find_track(start,ref_cycle,direction = direction)\n",
    "    track_name = 'SA' + str(track + 1)\n",
    "    \n",
    "    # download, read data from each cycle\n",
    "    for cycle in cycles:\n",
    "        cycle_data = Jason2.download.read_track(start,track_length,ref_cycle,cycle,reference_file)\n",
    "        if cycle_data == None:\n",
    "            continue\n",
    "        Hawaii_SA_raw[track_name][cycle] = cycle_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copernicus**\n",
    "\n",
    "(NOTE: change directory names to where nc files are stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories to retrieve nc files, initialize data structure\n",
    "dir_names = ['G:/copernicus_current_data/{year}/{year}'.format(year=year) for year in np.arange(2008,2017)]\n",
    "current_dataSA = dict()\n",
    "\n",
    "Hawaii_SA = Jason2.nested_dict()\n",
    "for t_num,t_name in enumerate(Hawaii_SA_raw.keys()):\n",
    "    \n",
    "    # preprocess data \n",
    "    Hawaii_SA[t_name] = Jason2.preprocess.preprocess_dataset(Hawaii_SA_raw[t_name],starts[t_num],distance_tol=15,masked_tol=5,supress_message=True)\n",
    "    \n",
    "    # find latitude and longitude range\n",
    "    lats = np.array([[Hawaii_SA[t_name][cycle]['lat'][0],Hawaii_SA[t_name][cycle]['lat'][-1]] for cycle in Hawaii_SA[t_name].keys()])\n",
    "    lons = np.array([[Hawaii_SA[t_name][cycle]['lon'][0],Hawaii_SA[t_name][cycle]['lon'][-1]] for cycle in Hawaii_SA[t_name].keys()])\n",
    "    lat_range = [min(lats[:,0]), max(lats[:,1])]\n",
    "    lon_range = [min(lons[:,0]), max(lons[:,1])]\n",
    "    \n",
    "    # download datasets from .nc directory (change directory name as necessary)\n",
    "    time,lat,lon,u,v = Jason2.download.read_current_data(lat_range,lon_range,dir_names)\n",
    "    current_dataSA[t_name] = dict(zip(['time','lat','lon','u','v'],[time,lat,lon,u,v]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ECCO version 4**\n",
    "\n",
    "(1) Use the bespoke Python package found [here](https://ecco-v4-python-tutorial.readthedocs.io/) to read in $\\frac{d \\rho}{dr}$ datasets.\n",
    "\n",
    "(2) Solve for buoyancy frequency using `Jason2_py.find_N_from_DRHODR()`\n",
    "\n",
    "(3) Use Dedalus to solve Sturm-Liouville BVP for horizontal velocities of internal tides (see [derivation](#derivation)). This can be done using script `dedalus\\solve_vertical_modes.py`\n",
    "\n",
    "For simplicity, we can just load the results from `mode_plot.py` from saved files:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dwnld'></a>\n",
    "**Download datasets from saved files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jason-2\n",
    "Hawaii_SA_raw = Jason2.nested_dict()\n",
    "with open('./test_data/Hawaii_SA_raw.csv', newline='') as csvfile:\n",
    "    \n",
    "    #initialize csv reader\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "    for i,row in enumerate(readCSV):\n",
    "        \n",
    "        # get track, cycle titles\n",
    "        if row[0] == 'track':\n",
    "            track = row[1]\n",
    "            continue\n",
    "        elif row[0] == 'cycle':\n",
    "            cycle = row[1]\n",
    "            continue\n",
    "        \n",
    "        # fill ssha data\n",
    "        else:\n",
    "            key = row[0]\n",
    "            _val = np.ma.masked_where(np.array(row[1::]) == '--',row[1::])\n",
    "            Hawaii_SA_raw[track][cycle][key] = np.ma.array([i if np.ma.array([i]).mask else float(i) for i in _val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copernicus\n",
    "current_dataSA = Jason2.nested_dict()\n",
    "with open('./test_data/current_dataSA.csv', newline='') as csvfile:\n",
    "    \n",
    "    # initialize csv reader\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    for i,row in enumerate(readCSV):\n",
    "        # get track name, and time, lat, and lon vectors\n",
    "        if row[0] == 'track':\n",
    "            track = row[1]\n",
    "            continue\n",
    "        if row[0] in ['time','lat','lon']:\n",
    "            current_dataSA[track][row[0]] = np.array([float(p.replace('[', '').replace(']', '')) for p in row[1::]])\n",
    "            \n",
    "            # once lat is defined, create matrix to store u and v\n",
    "            if row[0] == 'lon':\n",
    "                u_vel = np.zeros((len(current_dataSA[track]['time']),len(current_dataSA[track]['lat']),len(current_dataSA[track]['lon'])))\n",
    "                v_vel = np.zeros(np.shape(u_vel))\n",
    "                count_u = 0\n",
    "                count_v = 0\n",
    "            continue\n",
    "        \n",
    "        # check where to fill u or v values\n",
    "        if row[0] in ['u','v']:\n",
    "            key = row[0]\n",
    "            t_idx = np.where(current_dataSA[track]['time'] == float(row[2].replace('[', '').replace(']', '')))[0]\n",
    "            \n",
    "            if key == 'u':\n",
    "                vel = u_vel\n",
    "                count = count_u\n",
    "            else:\n",
    "                vel = v_vel\n",
    "                count = count_v\n",
    "                \n",
    "        # fill velocities, line by line\n",
    "        else:\n",
    "            vel[t_idx,count,:] =  row\n",
    "            count += 1\n",
    "            # save in dict once each time slice is filled\n",
    "            if t_idx == (len(current_dataSA[track]['time']) - 1):\n",
    "                current_dataSA[track][key] = vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECCOv4\n",
    "models = Jason2.nested_dict()\n",
    "tracks = ['SA' + str(i+1) for i in range(4)]\n",
    "for track in tracks:\n",
    "    modes = 1 / np.genfromtxt('./test_data/eigenvectors/modes%s.csv'%track,delimiter = ',')[:,1]\n",
    "    models[track]['M2 model']['wavenumber'] = modes[0]\n",
    "    models[track]['S2 model']['wavenumber'] = modes[1]\n",
    "    models[track]['eigenvectors'] = np.genfromtxt('./test_data\\eigenvectors\\%s.csv'%track,delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ascending Tracks\n",
    "In this demonstration, we will analyze the 2D power spectra of principal semi-diurnal internal tides (M2 and S2) along tracks South of the Hawaiian Ridge ([Figure 1](#Figure-1))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot 2D power spectrum**\n",
    "\n",
    "Now that the data is downloaded, let's look compute the 2D power spectrum using `Jason2_py.find_2D_power_spectrum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize plotting\n",
    "Hawaii_SA = Jason2.nested_dict()\n",
    "\n",
    "# starting coordinates\n",
    "starts = [[14.5,-167],\n",
    "          [13.5,-164.5],\n",
    "          [12.5,-162],\n",
    "          [10.5,-160]]\n",
    "\n",
    "\n",
    "for t_num, t_name in enumerate(Hawaii_SA_raw.keys()):\n",
    "    \n",
    "    # preprocess dataset\n",
    "    Hawaii_SA[t_name] = Jason2.preprocess.preprocess_dataset(Hawaii_SA_raw[t_name],starts[t_num],distance_tol=15,masked_tol=5,supress_message=True)\n",
    "    \n",
    "    # find power spectrum\n",
    "    fft_2D, dx, dt, nu_vector, f_vector = Jason2.find_2D_power_spectrum(Hawaii_SA[t_name])\n",
    "    \n",
    "    # find average lat and lon range\n",
    "    lats = np.array([[Hawaii_SA[t_name][cycle]['lat'][0],Hawaii_SA[t_name][cycle]['lat'][-1]] for cycle in Hawaii_SA[t_name].keys()])\n",
    "    lons = np.array([[Hawaii_SA[t_name][cycle]['lon'][0],Hawaii_SA[t_name][cycle]['lon'][-1]] for cycle in Hawaii_SA[t_name].keys()])\n",
    "    lat_range = [np.mean(lats[:,0]), np.mean(lats[:,1])]\n",
    "    lon_range = [np.mean(lons[:,0]), np.mean(lons[:,1])]\n",
    "    \n",
    "    # save info to models\n",
    "    models[t_name]['data'].update({'fft 2D' : fft_2D,\n",
    "                                  'dx': dx,\n",
    "                                  'dt': dt,\n",
    "                                  'wavenumbers' : nu_vector,\n",
    "                                  'frequencies' : f_vector,\n",
    "                                  'lat range' : lat_range,\n",
    "                                  'lon range' : lon_range})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we plot the surveyed Jason-2 tracks and their 2D power spectra:\n",
    "<a id='Figure-1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# draw plots\n",
    "track_dict = {'Track ' + str(i + 1) : pf.track_plt(models[track]['data'], 'Track ' + str(i + 1)) for i, track in enumerate(tracks)}\n",
    "power_dict = {'Track ' + str(i + 1) : pf.fft_2D_plt(models[track]['data'], '') for i, track in enumerate(tracks)}\n",
    "track_plot = hv.HoloMap(track_dict, kdims='Track').opts(infer_projection=True)\n",
    "power_plot = hv.HoloMap(power_dict, kdims='Track')\n",
    "(track_plot + power_plot).opts(title='Figure 1: 2D Power Spectra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=‚ÄôModels-for-Two-Dimensional-Fourier-Transform‚Äô></a>\n",
    "## Models for Two Dimensional Fourier Transform\n",
    "\n",
    "**Anisotropic Wave**\n",
    "\n",
    "We begin model tides as sinusoids given by the function: \n",
    "\n",
    "$$h(x,t) = A sin(2 \\pi (k x + \\omega t))$$ \n",
    "\n",
    "where $A$ is wave amplitude, $k$ is the tidal wavenumber and  $\\omega$ is the alias frequency. In our analysis, we minimize the effects of discontiuities by multiplying by a Hann window in both the space (x) and time (t). This window function is:\n",
    "\n",
    "$$w(x,t) = \\frac{1}{4}(1+cos(\\frac{2 \\pi x}{L})(1+cos(\\frac{2 \\pi t}{T}))rect(\\frac{x}{L})rect(\\frac{t}{T})$$\n",
    "\n",
    "where $L$ is the length of the track and $T$ is the length of the time window. Finally, to account for the discretization of the signal, we multiply by a Dirac comb given by:\n",
    "\n",
    "$$d(x,t) = \\sum^\\infty_{n=-\\infty}\\delta(t - n \\Delta t)\\sum^\\infty_{n=-\\infty}\\delta(x - n \\Delta x)$$\n",
    "\n",
    "where $\\Delta t$ and $\\Delta x$ are the time and space intervals between sucessive measurements. In total, our signal function is $s(x,t) = h(x,t) \\  w(x,t) \\ d(x,t)$. We would like to generate an analytical function for the two dimensional Fourier transform, $\\hat{s}(\\nu,f) = \\mathcal{F}[s(x,t)]$. Taking the fourier transforms of $h(x,t)$, $w(x,t)$, and $d(x,t)$, we have:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{h}(\\nu,f) &= \\frac{1}{2}A i \\Big(\\delta (\\nu + k) \\delta (f + \\omega) - \\delta (\\nu - k) \\delta (f - \\omega) \\Big) \\\\\n",
    "\\hat{w}(\\nu,f) &= \\frac{1}{4} \\Big(\\mathcal{F}[1 + cos(\\frac{2 \\pi x}{L})] * \\mathcal{F}[rect(\\frac{1}{L})]\\Big)\\Big(\\mathcal{F}[1 + cos(\\frac{2 \\pi t}{T})] * \\mathcal{F}[rect(\\frac{t}{T})]\\Big) \\\\\n",
    "&= \\frac{1}{4} \\Big[ \\Big(\\delta(\\nu) + \\frac{1}{2} \\delta (\\nu - 1/L) + \\frac{1}{2} \\delta (\\nu + 1/L)\\Big) *  L sinc(L \\nu) \\Big] \\Big[\\Big(\\delta(f) + \\frac{1}{2} \\delta (f - 1/T) + \\frac{1}{2} \\delta (f + 1/T)\\Big) *  T sinc(T f) \\Big] \\\\\n",
    "&= \\frac{1}{4}\\Big[ L sinc(L \\nu) + \\frac{1}{2} L sinc(L \\nu - 1) + \\frac{1}{2} L sinc(L \\nu + 1)\\Big]\\Big[ T sinc(T f) + \\frac{1}{2} T sinc(T f - 1) + \\frac{1}{2} T sinc(T f + 1)\\Big] \\\\\n",
    "\\hat{d}(\\nu,f) &= \\frac{1}{\\Delta x \\Delta t} \\sum^\\infty_{n=-\\infty}\\delta(\\nu - \\frac{n}{\\Delta x}) \\sum^\\infty_{n=-\\infty}\\delta(f - \\frac{n}{\\Delta t})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Thus, in total, we have the final analytical expression for the two-dimensional fourier transform of the signal:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{s}(\\nu,f) &= \\frac{A i}{8 \\Delta x \\Delta t} \\\\\n",
    "& \\times\\Big[   \\sum^\\infty_{n=-\\infty}\\Big(L sinc(L(\\nu - \\frac{n}{\\Delta x} + k)) + \\frac{1}{2} L sinc(L(\\nu - \\frac{n}{\\Delta x} + k) - 1) + \\frac{1}{2} L sinc(L(\\nu - \\frac{n}{\\Delta x} + k) + 1) \\Big)\\\\\n",
    "&\\times  \\sum^\\infty_{n=-\\infty}\\Big(T sinc(T(f - \\frac{n}{\\Delta t} + \\omega)) + \\frac{1}{2} T sinc(T(f - \\frac{n}{\\Delta t} + \\omega) - 1) + \\frac{1}{2} T sinc(T(f - \\frac{n}{\\Delta t} + \\omega) + 1) \\Big) \\\\\n",
    "&- \\sum^\\infty_{n=-\\infty}\\Big(L sinc(L(\\nu - \\frac{n}{\\Delta x} - k)) + \\frac{1}{2} L sinc(L(\\nu - \\frac{n}{\\Delta x} - k) - 1) + \\frac{1}{2} L sinc(L(\\nu - \\frac{n}{\\Delta x} - k) + 1) \\Big)\\\\\n",
    "&\\times  \\sum^\\infty_{n=-\\infty}\\Big(T sinc(T(f - \\frac{n}{\\Delta t} - \\omega)) + \\frac{1}{2} T sinc(T(f - \\frac{n}{\\Delta t} - \\omega) - 1) + \\frac{1}{2} T sinc(T(f - \\frac{n}{\\Delta t} - \\omega) + 1) \\Big) \\Big] \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The function `Jason2_py.model.power_spectrum()` computes the above result over a range of $n = [-50, 50]$. Let's use this to model the principal semi-diurnal tides, M2 (lunar) and S2 (solar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M2 and S2 tidal periods (hours)\n",
    "periods = [12.4206012,12]\n",
    "semidiurnals = ['M2 model', 'S2 model']\n",
    "for t_num, t_name in enumerate(tracks):\n",
    "    \n",
    "    # unpack parameters from data\n",
    "    track = models[t_name]['data']\n",
    "    dx = track['dx']\n",
    "    dt = track['dt']\n",
    "    nu_vector = track['wavenumbers']\n",
    "    f_vector = track['frequencies']\n",
    "    L = dx * len(nu_vector)\n",
    "    T = dt * len(f_vector)\n",
    "    fft_2D = track['fft 2D']\n",
    "    \n",
    "    for i,tide in enumerate(semidiurnals):\n",
    "        \n",
    "        model = models[t_name][tide]\n",
    "        k = model['wavenumber']\n",
    "        \n",
    "        # find alias frq from Jason-2 repeat period\n",
    "        w = Jason2.helper.find_alias_frq(9.9156,periods[i]/24)\n",
    "        model['alias frq'] = w\n",
    "        \n",
    "        # simulate spectrum, unit amplitude\n",
    "        model_spectrum = Jason2.model.power_spectrum(1,L,nu_vector,k,T,w,f_vector,dx,dt)\n",
    "    \n",
    "        # fit model to predicted tidal peak, save values for plotting \n",
    "        model['fft 2D'] = Jason2.model.fit_models([[k,w]],nu_vector,f_vector,fft_2D, [model_spectrum]) * model_spectrum\n",
    "        model['wavenumbers'] = nu_vector\n",
    "        model['frequencies'] = f_vector\n",
    "        model['frequencies'] = f_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the model to the data (Figure 2):\n",
    "<a id='Figure-2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore')\n",
    "# put plots into dict\n",
    "_model_p = dict()\n",
    "for i, track in enumerate(tracks):\n",
    "    for tide in ['M2 model', 'S2 model']:\n",
    "        _model_p[(tide.replace(\" model\",\"\"),'Track ' + str(i + 1))] = pf.fft_2D_plt(models[track][tide],'model')\n",
    "\n",
    "# make drop-down list\n",
    "model_p = hv.HoloMap(_model_p, kdims=['Tide','Track'])\n",
    "\n",
    "# plot overlay\n",
    "(track_plot + \n",
    " power_plot.opts(width =300, \n",
    "                 height = 300,\n",
    "                 title='data',\n",
    "                 colorbar=False) + \n",
    " model_p.opts(width =300,\n",
    "         height = 300,\n",
    "         title='model')).opts(title='Figure 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot cross-sections centered at the estimated tidal peaks (Figure 3):\n",
    "<a id='Figure-3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize dict to hold plots\n",
    "_f = dict()\n",
    "_nu = dict()\n",
    "for i, track in enumerate(tracks):\n",
    "    \n",
    "    # get data spectrum\n",
    "    data = models[track]['data']\n",
    "    for tide in ['M2 model', 'S2 model']:\n",
    "        \n",
    "        # get model spectrum\n",
    "        model = models[track][tide]\n",
    "        val_f = model['alias frq']\n",
    "        val_nu = model['wavenumber']\n",
    "        \n",
    "        # make individual line plots\n",
    "        mf = pf.line_plt(model,'f',val_nu).relabel('model')\n",
    "        df = pf.line_plt(data,'f',val_nu).relabel('data')\n",
    "        mnu = pf.line_plt(model,'nu',val_f).relabel('model')\n",
    "        dnu = pf.line_plt(data,'nu',val_f).relabel('data')\n",
    "        \n",
    "        # make overlay dicts\n",
    "        _f[(tide.replace(\" model\",\"\"),'Track ' + str(i + 1))] = (df * mf).opts(projection=ccrs.PlateCarree(),legend_position='top_left')\n",
    "        _nu[(tide.replace(\" model\",\"\"),'Track ' + str(i + 1))] = (dnu * mnu).opts(projection=ccrs.PlateCarree(),legend_position='top_left')\n",
    "\n",
    "# # Make drop down list\n",
    "f = hv.HoloMap(_f, kdims=['Tide','Track']).opts(infer_projection=True)\n",
    "nu = hv.HoloMap(_nu, kdims=['Tide','Track']).opts(infer_projection=True)\n",
    "\n",
    "# # plot layout\n",
    "(f + nu).opts(title='Figure 3',shared_axes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anisotropic Wave with Frequency Doppler Shift**\n",
    "\n",
    "Comparing our M2 model to the data in frequency space, we find that the tidal peak is blue-shifted and broader than the model predicts. A possible explanation for this discrepancy is the effect of Doppler shifting by mean flows South of the Hawaiian Ridge. To examine this, we refine our model to include a time-dependent advection term using data from [Copernicus](https://cds.climate.copernicus.eu/cdsapp#!/dataset/satellite-sea-level-global?tab=overview). The Dopper shifted frequencies are calculated as:\n",
    "\n",
    "$$\\omega_t = \\omega + {\\overline{U}} \\cdot \\nu$$\n",
    "\n",
    "where $\\overline{U}$ is the current velocity averaged over the water column, $\\nu$ is the tidal wavenumber, and  $\\omega$ is the alias frequency. \n",
    "\n",
    "First, We can plot the surface velocities near the tracks (Figure 4):\n",
    "<a id='Figure-4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_U = {'Track ' + str(i + 1) : pf.U_plt(current_dataSA[track],models[track]['data'],\"\") for i, track in enumerate(tracks)}\n",
    "U = hv.HoloMap(_U, kdims='Track').opts(infer_projection=True)\n",
    "U.opts(title='Figure 4: Surface Current Magnitudes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, from the average surface velocity, we would expect the maximum magntiude of Doppler-shifting to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,track in enumerate(tracks):\n",
    "    theta = np.arctan(np.diff(models[track]['data']['lat range']) / np.diff(models[track]['data']['lat range']))\n",
    "    u = np.mean(current_dataSA[track]['u'])\n",
    "    v = np.mean(current_dataSA[track]['v'])\n",
    "    mag = np.sqrt(u**2 + v**2) * np.cos(theta)\n",
    "    print(mag[0] * 24 * 3600 / 1000 * models[track]['M2 model']['wavenumber'], ' 1/day for track', str(i+1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, a better approximation would be to take the depth-averaged velocities, which can be found by solving for the vertical modes, as derived below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='derivation'></a>\n",
    "**Calculation of $k$ and $ U$**\n",
    "\n",
    "The horizontal velocities of internal tides for a rigid-lid, flat-bottom ocean are described by the following Sturm-Liouville boundary value problem [(1)](https://oceanphysics.files.wordpress.com/2019/08/jpo-d-18-0272.1-1.pdf).:\n",
    "\n",
    "$$\\frac{d}{dz}\\Big(\\frac{1}{N^2}\\frac{dF}{dz}\\Big) + \\frac{1}{c^2}F = 0, \\\\ \\frac{dF}{dz} = 0 \\ \\ \\ \\ \\text{at} \\ \\ \\ \\ z = 0 \\ \\ \\ \\ \\text{ and} \\ \\ \\ \\ z= -H$$ \n",
    "\n",
    "where $H$ is ocean depth and $N$ is the buoyancy frequency. The eigenvalue solutions (vertical modes), $F_n$, have associated eigenvalues of $-1/c_n^2$, and the tidal wavneumber is calculated using the dispersion relationship:\n",
    "\n",
    "$$k_n = \\frac{(\\omega^2 - f^2)^{1/2}}{c_n}$$\n",
    "\n",
    "where $f$ is the coriolis parameter and $\\omega$ is the tidal frequency (e.g. reported [here](https://en.wikipedia.org/wiki/Theory_of_tides#:~:text=The%20theory%20of%20tides%20is,especially%20the%20Moon%20and%20Sun)). $F_n$ are solved using the [dedalus framework](http://dedalus-project.org/) with stratification from ECCO version 4. Estimates of current velocity are done by assuming horizontal velocities are given by \n",
    "\n",
    "$$U = A_1 F_1 + A_2 F_2, \\\\  U = 0  \\ \\ \\ \\ \\text{at} \\ \\ \\ \\ z = -H  \\ \\ \\ \\ \\text{and} \\ \\ \\ \\ U = U_1 \\ \\ \\ \\ \\text{at} \\ \\ \\ \\ z = 0$$\n",
    "\n",
    "where $U_1$ is the current velocity reported by Copernicus projected on the Jason-2 track. In our model, `Jason2_py.model.doppler_power_spectrum()`, we simulate a power spectrum for each Jason-2 pass using the $\\omega_t$ from that day and report the average of all simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for t_num, t_name in enumerate(tracks):\n",
    "    \n",
    "    data = models[t_name]['data']\n",
    "    eigenvector = models[t_name]['eigenvectors'][2,:]\n",
    "    c_data = current_dataSA[t_name]\n",
    "    for tide in ['M2 model', 'S2 model']:\n",
    "        print('simulating track ' + ''.join([str(t_num + 1), ' ', tide]))\n",
    "        model = models[t_name][tide]\n",
    "    \n",
    "        # evaluate doppler model\n",
    "        args = (data['lat range'],\n",
    "               data['lon range'],\n",
    "               data['frequencies'],\n",
    "               data['wavenumbers'],\n",
    "               model['alias frq'],\n",
    "               data['dx'] * len(data['wavenumbers']),\n",
    "               model['wavenumber'],\n",
    "               data['dt'] * len(data['frequencies']),\n",
    "               data['dx'],\n",
    "               data['dt'],\n",
    "               data['fft 2D'])\n",
    "        \n",
    "        w_t,power_spec  = Jason2.model.doppler_power_spectrum(eigenvector,c_data,Hawaii_SA[t_name],args)\n",
    "        \n",
    "        # fit model to tidal wavenumber and alias frequency\n",
    "        coeff = Jason2.model.fit_models([[args[6],np.mean(w_t)]],args[3],args[2],args[-1], [power_spec])\n",
    "        fft_2D = coeff * power_spec\n",
    "\n",
    "        # store values\n",
    "        models[t_name]['doppler ' + tide] = {'wavenumber' : model['wavenumber'],\n",
    "                                             'alias frq'  : model['alias frq'],\n",
    "                                             'shifted frequencies' : w_t,\n",
    "                                             'fft 2D' : fft_2D,\n",
    "                                             'wavenumbers' : data['wavenumbers'],\n",
    "                                             'frequencies' : data['frequencies']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the $ \\omega_t$ over all Jason-2 cycles, we have the following distribution (Figure 5):\n",
    "<a id='Figure-5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_wt = dict()\n",
    "for i, track in enumerate(tracks):\n",
    "    frequencies, edges = np.histogram(models[track]['doppler M2 model']['shifted frequencies'], 20)\n",
    "    title = 'Alias Frequency: %.5f 1/day'%models[track]['M2 model']['alias frq']\n",
    "    _wt['Track ' + str(i + 1)] = hv.Histogram((edges, frequencies)).opts(xlabel = 'ùúî‚Çú (1/day)',\n",
    "                                                                         title = title,\n",
    "                                                                         fontsize = {'labels':12})\n",
    "wt = hv.HoloMap(_wt, kdims='Track').opts(title='Figure 5')\n",
    "wt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the power spectra of the doppler simulations and their cross-sections (Figure 6 and 7):\n",
    "<a id='Figure-6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# put plots into dict\n",
    "_doppler = dict()\n",
    "for i, track in enumerate(tracks):\n",
    "    for tide in ['M2 model', 'S2 model']:\n",
    "        _doppler[(tide.replace(\" model\",\"\"),'Track ' + str(i + 1))] = pf.fft_2D_plt(models[track]['doppler ' + tide],'doppler model')\n",
    "\n",
    "# make drop-down list\n",
    "doppler = hv.HoloMap(_doppler, kdims=['Tide','Track']).opts(width =300,height = 300)\n",
    "\n",
    "# plot overlay\n",
    "p1 = power_plot.opts(width = 250, height = 300,title='data', colorbar=False)\n",
    "p2 = model_p.opts(width = 250,height = 300,title='model',colorbar=False)\n",
    "(p1 + p2 + doppler).opts(title='Figure 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize dict to hold plots\n",
    "_frq = dict()\n",
    "_om = dict()\n",
    "for i, track in enumerate(tracks):\n",
    "    \n",
    "    # get data spectrum\n",
    "    data = models[track]['data']\n",
    "    \n",
    "    for tide in ['M2 model', 'S2 model']:\n",
    "        \n",
    "        # get model spectrum\n",
    "        model = models[track][tide]\n",
    "        dmodel = models[track]['doppler ' + tide]\n",
    "        val_f = model['alias frq']\n",
    "        val_nu = model['wavenumber']\n",
    "        \n",
    "        # make individual line plots\n",
    "        df = pf.line_plt(data,'f',val_nu).relabel('data')\n",
    "        mf = pf.line_plt(model,'f',val_nu).relabel('model')\n",
    "        dmf = pf.line_plt(dmodel,'f',val_nu).relabel('doppler model')\n",
    "        dnu = pf.line_plt(data,'nu',val_f).relabel('data')\n",
    "        mnu = pf.line_plt(model,'nu',val_f).relabel('model')\n",
    "        dmnu = pf.line_plt(dmodel,'nu',val_f).relabel('doppler model')\n",
    "        \n",
    "        # make overlay dicts\n",
    "        _frq[(tide.replace(' model',''),'Track ' + str(i + 1))] = (df * mf * dmf).opts(projection=ccrs.PlateCarree(),legend_position='top_left')\n",
    "        _om[(tide.replace(' model',''),'Track ' + str(i + 1))] = (dnu * mnu * dmnu).opts(projection=ccrs.PlateCarree(),legend_position='top_left')\n",
    "\n",
    "# Make drop down list\n",
    "frq = hv.HoloMap(_frq, kdims=['Tide','Track']).opts(infer_projection=True)\n",
    "om = hv.HoloMap(_om, kdims=['Tide','Track']).opts(infer_projection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Figure-7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot layout\n",
    "(frq.opts(width=450) + om.opts(width=400)).opts(title='Figure 7',shared_axes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have a summary of mean square error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ranges (track x frequency range x wavenumber range)\n",
    "ranges = np.array([[[.008,.03],[0.0055,0.008]],\n",
    "                  [[.01,.03],[.003,.0085]],\n",
    "                  [[0.000,.04,],[.005,.0075]],\n",
    "                  [[.01,.025],[.005,.009]]])\n",
    "\n",
    "# calculate mean square error\n",
    "mse = np.zeros((4,2,2))\n",
    "_range = dict()\n",
    "for t_num,t_name in enumerate(tracks):\n",
    "    \n",
    "    # get ranges\n",
    "    f_range = ranges[t_num,0,:].tolist()\n",
    "    nu_range = ranges[t_num,1,:].tolist()\n",
    "    _range['Track ' + str(t_num + 1)] = pf.fft_2D_plt(models[t_name]['data'],'').opts(xlim=tuple(nu_range),\n",
    "                                                                                     ylim=tuple(f_range))\n",
    "    # get data spectrum\n",
    "    power_spectrum = models[t_name]['data']\n",
    "    f_vector = power_spectrum['frequencies']\n",
    "    nu_vector = power_spectrum['wavenumbers']\n",
    "    for tide_num, tide in enumerate(['M2 model', 'S2 model']):\n",
    "        \n",
    "        # get model specta\n",
    "        model = models[t_name][tide]['fft 2D']\n",
    "        dmodel = models[t_name]['doppler ' + tide]['fft 2D']\n",
    "        \n",
    "        # solve for mean square error\n",
    "        mse[t_num,tide_num,0] = Jason2.find_square_error(f_range, \n",
    "                                                         nu_range,\n",
    "                                                         f_vector,\n",
    "                                                         nu_vector,\n",
    "                                                         power_spectrum['fft 2D'],\n",
    "                                                         model)\n",
    "        mse[t_num,tide_num,1]= Jason2.find_square_error(f_range,\n",
    "                                                        nu_range,\n",
    "                                                        f_vector,\n",
    "                                                        nu_vector,\n",
    "                                                        power_spectrum['fft 2D'],\n",
    "                                                        dmodel)\n",
    "# output\n",
    "range_plt = hv.HoloMap(_range, kdims='Track').opts(framewise=True,\n",
    "                                                  width=400,height=300)\n",
    "d = dict()\n",
    "d['M2'] = pd.DataFrame(columns=['Model', 'Doppler Model',],\n",
    "                                data=mse[:,0,:],\n",
    "                                index = ['Track %.f'%(i+1) for i in range(4)])\n",
    "\n",
    "d['S2'] = pd.DataFrame(columns=['Model', 'Doppler Model',],\n",
    "                                data=mse[:,1,:],\n",
    "                                index = ['Track %.f'%(i+1) for i in range(4)])\n",
    "\n",
    "pd.set_option('display.float_format', '{:.2E}'.format)\n",
    "df = pd.concat(d, axis=1,names=['Tidal Constituent:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Table 1: Mean Square Error')\n",
    "display(HTML(df.to_html()))\n",
    "range_plt.opts(title='Figure 8: Semi-Diurnal Peaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus over the ranges selected, we see that the Doppler Model reduces the mean square error for all but track 4. Let's now see if we can pick up the same tidal signals from the descending tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descending Tracks\n",
    "Click [here](#dwnld1) to load data (or run next two code cells)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Jason-2 Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get existing cycles:\n",
    "f = open(\"cycles.txt\", \"r\")\n",
    "cycles = [line.strip()[1:4] for line in f]\n",
    "\n",
    "# define reference cycle\n",
    "ref_cycle = '100'\n",
    "\n",
    "# target start point and track length\n",
    "starts = [[22.450964, -168.03407],\n",
    "          [21.74352, -164.891574],\n",
    "          [20.98662, -161.731304],\n",
    "          [18.619012, -160.738939]]\n",
    "track_length = 1000\n",
    "direction = 'S'\n",
    "\n",
    "# download and read ssha data for ascending tracks South of Hawaiian Ridge\n",
    "Hawaii_SD_raw = Jason2.nested_dict()\n",
    "for track in range(4):\n",
    "   \n",
    "    # define start and reference file:\n",
    "    start = starts[track]\n",
    "    reference_file = Jason2.download.find_track(start,ref_cycle,direction = direction)\n",
    "    track_name = 'SD' + str(track + 1)\n",
    "    \n",
    "    # download, read data from each cycle\n",
    "    for cycle in cycles:\n",
    "        cycle_data = Jason2.download.read_track(start,track_length,ref_cycle,cycle,reference_file)\n",
    "        if cycle_data == None:\n",
    "            continue\n",
    "        Hawaii_SD_raw[track_name][cycle] = cycle_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Copernicus Data** (set directory name as necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories to retrieve nc files, initialize data structure\n",
    "dir_names = ['G:/copernicus_current_data/{year}/{year}'.format(year=year) for year in np.arange(2008,2017)]\n",
    "current_dataSD = dict()\n",
    "\n",
    "Hawaii_SD = Jason2.nested_dict()\n",
    "lat_range = np.zeros((4,2))\n",
    "lon_range = np.zeros((4,2))\n",
    "for t_num, t_name in enumerate(Hawaii_SD_raw.keys()):\n",
    "    \n",
    "    # preprocess data\n",
    "    Hawaii_SD[t_name] = Jason2.preprocess.preprocess_dataset(Hawaii_SD_raw[t_name],starts[t_num],masked_tol=5)\n",
    "    \n",
    "    # find latitude and longitude range\n",
    "    lats = np.array([[Hawaii_SD[t_name][cycle]['lat'][0],Hawaii_SD[t_name][cycle]['lat'][-1]] for cycle in Hawaii_SD[t_name].keys()])\n",
    "    lons = np.array([[Hawaii_SD[t_name][cycle]['lon'][0],Hawaii_SD[t_name][cycle]['lon'][-1]] for cycle in Hawaii_SD[t_name].keys()])\n",
    "    lat_range = [min(lats[:,1]), max(lats[:,0])]\n",
    "    lon_range = [min(lons[:,0]), max(lons[:,1])]\n",
    "    \n",
    "    # download datasets from .nc directory (change directory name as necessary)\n",
    "    time,lat,lon,u,v = Jason2.download.read_current_data(lat_range,lon_range,dir_names)\n",
    "    current_dataSD[t_name] = dict(zip(['time','lat','lon','u','v'],[time,lat,lon,u,v]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dwnld1'></a>\n",
    "**Load Descending Track Data from saved files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./test_data/Hawaii_SD_raw.csv', 'w',newline=\"\") as csv_file:\n",
    "#     csvwriter = csv.writer(csv_file)\n",
    "#     for t_num, track in enumerate(Hawaii_SD_raw):\n",
    "#         csvwriter.writerow(['track',track])\n",
    "#         for cycle in Hawaii_SD_raw[track].keys():\n",
    "#             csvwriter.writerow(['cycle',cycle])\n",
    "#             for key,val in Hawaii_SD_raw[track][cycle].items():\n",
    "#                 jason2_list = [0] * (len(val) + 1)\n",
    "#                 jason2_list[0] = key\n",
    "#                 jason2_list[1::] = val\n",
    "#                 csvwriter.writerow(jason2_list)\n",
    "                \n",
    "# with open('./test_data/current_dataSD.csv', 'w',newline=\"\") as csv_file:\n",
    "#     csvwriter = csv.writer(csv_file)\n",
    "#     for t_num, track in enumerate(current_dataSD):\n",
    "#         csvwriter.writerow(['track',track])\n",
    "#         time = current_dataSD[track]['time']\n",
    "#         for key,val in currents_SD[track].items():\n",
    "#             if key != 'u' and key != 'v':\n",
    "#                 jason2_list = [0] * (len(val) + 1)\n",
    "#                 jason2_list[0] = key\n",
    "#                 jason2_list[1::] = val\n",
    "#                 csvwriter.writerow(jason2_list)\n",
    "#             else:\n",
    "                \n",
    "#                 for idx,t in enumerate(time):\n",
    "#                     csvwriter.writerow([key,'slice time', t])\n",
    "#                     csvwriter.writerows(val[idx,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jason-2\n",
    "Hawaii_SD_raw = Jason2.nested_dict()\n",
    "with open('./test_data/Hawaii_SD_raw.csv', newline='') as csvfile:\n",
    "    \n",
    "    # initialize csv reader\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    for i,row in enumerate(readCSV):\n",
    "        \n",
    "        # get track and cycle names\n",
    "        if row[0] == 'track':\n",
    "            track = row[1]\n",
    "            continue\n",
    "        elif row[0] == 'cycle':\n",
    "            cycle = row[1]\n",
    "            continue\n",
    "        \n",
    "        # fill ssha values\n",
    "        else:\n",
    "            key = row[0]\n",
    "            _val = np.ma.masked_where(np.array(row[1::]) == '--',row[1::])\n",
    "            Hawaii_SD_raw[track][cycle][key] = np.ma.array([i if np.ma.array([i]).mask else float(i) for i in _val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copernicus\n",
    "current_dataSD = Jason2.nested_dict()\n",
    "with open('./test_data/current_dataSD.csv', newline='') as csvfile:\n",
    "    \n",
    "    # initialize csv reader\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    for i,row in enumerate(readCSV):\n",
    "        \n",
    "        # get track name, and time, lat, and lon vectors\n",
    "        if row[0] == 'track':\n",
    "            track = row[1]\n",
    "            continue\n",
    "        if row[0] in ['time','lat','lon']:\n",
    "            current_dataSD[track][row[0]] = np.array([float(p.replace('[', '').replace(']', '')) for p in row[1::]])\n",
    "            \n",
    "            # once lat is defined, create matrix to store u and v\n",
    "            if row[0] == 'lon':\n",
    "                u_vel = np.zeros((len(current_dataSD[track]['time']),len(current_dataSD[track]['lat']),len(current_dataSD[track]['lon'])))\n",
    "                v_vel = np.zeros(np.shape(u_vel))\n",
    "                count_u = 0\n",
    "                count_v = 0\n",
    "            continue\n",
    "        \n",
    "        # check where to fill u or v values\n",
    "        if row[0] in ['u','v']:\n",
    "            key = row[0]\n",
    "            t_idx = np.where(current_dataSD[track]['time'] == float(row[2].replace('[', '').replace(']', '')))[0]\n",
    "            \n",
    "            if key == 'u':\n",
    "                vel = u_vel\n",
    "                count = count_u\n",
    "            else:\n",
    "                vel = v_vel\n",
    "                count = count_v\n",
    "                \n",
    "        # fill velocities, line by line\n",
    "        else:\n",
    "            vel[t_idx,count,:] =  row\n",
    "            count += 1\n",
    "            # save in dict once each time slice is filled\n",
    "            if t_idx == (len(current_dataSD[track]['time']) - 1):\n",
    "                current_dataSD[track][key] = vel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECCOv4\n",
    "tracksd = ['SD' + str(i+1) for i in range(4)]\n",
    "for track in tracksd:\n",
    "    modes = 1 / np.genfromtxt('./test_data\\eigenvectors\\modes%s.csv'%track,delimiter = ',')[:,1]\n",
    "    models[track]['M2 model']['wavenumber'] = modes[0]\n",
    "    models[track]['S2 model']['wavenumber'] = modes[1]\n",
    "    models[track]['eigenvectors'] = np.genfromtxt('./test_data\\eigenvectors\\%s.csv'%track,delimiter = ',')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angular Dependence of Tidal Wavenumber\n",
    "Unlike the ascending tracks, we assume that waves do not propagate collinearly with the Jason-2 tracks. Thus, the effective wavenumbers used to describe the observed 2D power spectra are given as:\n",
    "\n",
    "$$k_{eff} = k \\ cos(\\theta)$$\n",
    "\n",
    "where $k$ is the expected tidal wavenumber, and $\\theta$ is the angle between the  tide beam and the track. Since we wnat to model the strong semi-dirunal signals found in the ascending tracks, we have chosen 4 descending tracks whose midpoints are closest to the respective midpoints of the 4 ascending tracks. This choice was made because the Hann window places greater weight on values near the center of each track.\n",
    "\n",
    "Below, we calculate $\\theta$ for each track by simply taking the angle between each ascending-descending track pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hawaii_SD = Jason2.nested_dict()\n",
    "_trkd = dict()\n",
    "_trk = dict()\n",
    "tracksd = ['SD' + str(i+1) for i in range(4)]\n",
    "starts = [[22.450964, -168.03407],\n",
    "          [21.74352, -164.891574],\n",
    "          [20.98662, -161.731304],\n",
    "          [18.619012, -160.738939]]\n",
    "\n",
    "thetas = [0] * 4\n",
    "for t_num, t_name in enumerate(tracksd):\n",
    "    \n",
    "    # preprocess data\n",
    "    Hawaii_SD[t_name] = Jason2.preprocess.preprocess_dataset(Hawaii_SD_raw[t_name],starts[t_num],masked_tol=5)  \n",
    "    \n",
    "    # find average lat and lon range\n",
    "    lats = np.array([[Hawaii_SD[t_name][cycle]['lat'][0],Hawaii_SD[t_name][cycle]['lat'][-1]] for cycle in Hawaii_SD[t_name].keys()])\n",
    "    lons = np.array([[Hawaii_SD[t_name][cycle]['lon'][0],Hawaii_SD[t_name][cycle]['lon'][-1]] for cycle in Hawaii_SD[t_name].keys()])\n",
    "    lat_range = [np.mean(lats[:,0]), np.mean(lats[:,1])]\n",
    "    lon_range = [np.mean(lons[:,0]), np.mean(lons[:,1])]\n",
    "    \n",
    "    # save info to models\n",
    "    models[t_name]['data'].update({'lat range' : lat_range,\n",
    "                                  'lon range' : lon_range})\n",
    "    \n",
    "    # find track angles:\n",
    "    data_a = models['SA' + str(t_num + 1)]['data']\n",
    "    data_d = models[t_name]['data']\n",
    "    v_a = [np.diff(data_a['lat range'])[0],np.diff(data_a['lon range'])[0]]\n",
    "    v_d = [np.diff(data_d['lat range'])[0],np.diff(data_d['lon range'])[0]]\n",
    "    thetas[t_num] = np.arccos(np.dot(v_d/np.linalg.norm(v_d),v_a/np.linalg.norm(v_a)))\n",
    "    \n",
    "    # create plot dicts\n",
    "    _trkd['Track ' + str(t_num+1)] = pf.track_plt(models[t_name]['data'],\"Track %.f\"%(t_num+1))\n",
    "    _trk['Track ' + str(t_num+1)] = (track_dict['Track ' + str(t_num+1)] * _trkd['Track ' + str(t_num+1)]).opts(projection = ccrs.PlateCarree(),\n",
    "                                                                                                                title='Figure 9: Œ∏ = %.3f'%thetas[t_num]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make drop down plots\n",
    "trk = hv.HoloMap(_trk,kdims=['Track'])\n",
    "trk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the 2D power spectra of the descending tracks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_powerd = dict()\n",
    "for t_num, t_name in enumerate(tracksd):\n",
    "    \n",
    "    # preprocess data\n",
    "    Hawaii_SD[t_name] = Jason2.preprocess.preprocess_dataset(Hawaii_SD_raw[t_name],starts[t_num],masked_tol=5)    \n",
    "    \n",
    "    # find power spectrum\n",
    "    fft_2D, dx, dt, nu_vector, f_vector = Jason2.find_2D_power_spectrum(Hawaii_SD[t_name])\n",
    "    \n",
    "    # save info to models\n",
    "    models[t_name]['data'].update({'fft 2D' : fft_2D,\n",
    "                                  'dx': dx,\n",
    "                                  'dt': dt,\n",
    "                                  'wavenumbers' : nu_vector,\n",
    "                                  'frequencies' : f_vector})\n",
    "    \n",
    "    # Make heatmaps\n",
    "    _powerd['Track ' + str(t_num + 1)] = pf.fft_2D_plt(models[t_name]['data'], '')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make drop-down plots\n",
    "powerd = hv.HoloMap(_powerd, kdims=['Track'])\n",
    "(trk.opts(title='',infer_projection=True,height=200,width=200) +\n",
    " power_plot.opts(title='Ascending',height=300,width=300) +\n",
    " powerd.opts(title='Descending',height=300,width=300)).opts(title='Figure 10: 2D Power Spectra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we are fitting to the peaks where the tidal wavenumber and alias frequency are opposite in sign. Now, let's turn to modeling. Plotting the surface currents we see similar magnitudes as for the ascending tracks, so we expect the Doppler shifting of the alias frequency to be a factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_Ud = {'Track ' + str(i + 1) : pf.U_plt(current_dataSD[track],models[track]['data'],\"\") for i, track in enumerate(tracksd)}\n",
    "Ud = hv.HoloMap(_Ud, kdims='Track').opts(infer_projection=True)\n",
    "Ud.opts(title='Figure 11: Mean Flow at Surface')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute both the simple and Doppler model, and update our dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# M2 and S2 tidal periods (hours)\n",
    "periods = [12.4206012,12]\n",
    "semidiurnals = ['M2 model', 'S2 model']\n",
    "\n",
    "for t_num, t_name in enumerate(tracksd):\n",
    "    \n",
    "    # get data\n",
    "    c_data = current_dataSD[t_name]\n",
    "    data = models[t_name]['data']\n",
    "    eigenvector = models[t_name]['eigenvectors'][2,:] # 2nd vertical mode\n",
    "    dx = data['dx']\n",
    "    dt = data['dt']\n",
    "    nu_vector = data['wavenumbers']\n",
    "    f_vector = data['frequencies']\n",
    "    L = dx * len(nu_vector)\n",
    "    T = dt * len(f_vector)\n",
    "    fft_2D = data['fft 2D']\n",
    "    \n",
    "    for i,sdiurnal in enumerate(semidiurnals):\n",
    "        \n",
    "        model = models[t_name][sdiurnal]\n",
    "        k = model['wavenumber']\n",
    "        \n",
    "        # multiply k by track angle\n",
    "        k_eff = k * np.cos(thetas[t_num])\n",
    "        \n",
    "        # find alias frq from Jason-2 repeat period\n",
    "        w = Jason2.helper.find_alias_frq(9.9156,periods[i]/24)\n",
    "        model['alias frq'] = w\n",
    "        \n",
    "        \n",
    "        #-------Model 1: No Doppler shift--------\n",
    "        print('simulating track ' + ''.join([str(t_num + 1), ' ', sdiurnal]))\n",
    "        model_spectrum = Jason2.model.power_spectrum(1,L,nu_vector,k_eff,T,w,f_vector,dx,dt)\n",
    "        model['fft 2D'] = Jason2.model.fit_models([[k_eff,w]],nu_vector,f_vector,fft_2D, [model_spectrum]) * model_spectrum\n",
    "        model['wavenumbers'] = nu_vector\n",
    "        model['frequencies'] = f_vector\n",
    "        model['frequencies'] = f_vector\n",
    "        model['effective wavenumber'] = k_eff\n",
    "        \n",
    "        #-------Model 2: Doppler Shift---------\n",
    "        args = (data['lat range'],\n",
    "               data['lon range'],\n",
    "               data['frequencies'],\n",
    "               data['wavenumbers'],\n",
    "               model['alias frq'],\n",
    "               data['dx'] * len(data['wavenumbers']),\n",
    "               k_eff,\n",
    "               data['dt'] * len(data['frequencies']),\n",
    "               data['dx'],\n",
    "               data['dt'],\n",
    "               data['fft 2D'])\n",
    "        \n",
    "        w_t,power_spec  = Jason2.model.doppler_power_spectrum(eigenvector,c_data,Hawaii_SD[t_name],args)\n",
    "        \n",
    "        # fit model to tidal wavenumber and average Doppler-shifted frequency\n",
    "        coeff = Jason2.model.fit_models([[args[6],np.mean(w_t)]],args[3],args[2],args[-1], [power_spec])\n",
    "        fft_2D = coeff * power_spec\n",
    "        models[t_name]['doppler ' + sdiurnal] = {'wavenumber' : model['wavenumber'],\n",
    "                                                'effective wavenumber' : k_eff,\n",
    "                                                'alias frq'  : model['alias frq'],\n",
    "                                                'shifted frequencies' : w_t,\n",
    "                                                'fft 2D' : fft_2D,\n",
    "                                                'wavenumbers' : data['wavenumbers'],\n",
    "                                                'frequencies' : data['frequencies']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# put plots into dict\n",
    "_modeld = dict()\n",
    "_dmodeld = dict()\n",
    "for i, track in enumerate(tracksd):\n",
    "    for tide in ['M2 model', 'S2 model']:\n",
    "        _modeld[(tide.replace(\" model\",\"\"),'Track ' + str(i + 1))] = pf.fft_2D_plt(models[track][tide],'model')\n",
    "        _dmodeld[(tide.replace(\" model\",\"\"),'Track ' + str(i + 1))] = pf.fft_2D_plt(models[track]['doppler ' + tide],'model')\n",
    "# make drop-down list\n",
    "modeld = hv.HoloMap(_modeld, kdims=['Tide','Track'])\n",
    "dmodeld = hv.HoloMap(_dmodeld, kdims=['Tide','Track'])\n",
    "trkd = hv.HoloMap(_trkd, kdims =['Track']).opts(infer_projection=True)\n",
    "\n",
    "# plot overlay\n",
    "(powerd.opts(width =250, \n",
    "                 height = 300,\n",
    "                 title='data',\n",
    "                 colorbar=False) + \n",
    " modeld.opts(width =250,\n",
    "         height = 300,\n",
    "         title='model',\n",
    "         colorbar=False) + \n",
    " dmodeld.opts(width =300,\n",
    "         height = 300,\n",
    "         title='Doppler model')).opts(title='Figure 12: 2D models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(powerd + modeld).opts(shared_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dict to hold plots\n",
    "_frqd = dict()\n",
    "_omd = dict()\n",
    "for i, track in enumerate(tracksd):\n",
    "    \n",
    "    # get data spectrum\n",
    "    data = models[track]['data']\n",
    "    \n",
    "    for tide in ['M2 model', 'S2 model']:\n",
    "        \n",
    "        # get model spectrum\n",
    "        model = models[track][tide]\n",
    "        dmodel = models[track]['doppler ' + tide]\n",
    "        val_f = model['alias frq']\n",
    "        val_nu = model['effective wavenumber']\n",
    "        \n",
    "        # make individual line plots\n",
    "        dfd = pf.line_plt(data,'f',val_nu).relabel('data')\n",
    "        mfd = pf.line_plt(model,'f',val_nu).relabel('model')\n",
    "        dmfd = pf.line_plt(dmodel,'f',val_nu).relabel('doppler model')\n",
    "        dnud = pf.line_plt(data,'nu',val_f).relabel('data')\n",
    "        mnud = pf.line_plt(model,'nu',val_f).relabel('model')\n",
    "        dmnud = pf.line_plt(dmodel,'nu',val_f).relabel('doppler model')\n",
    "        \n",
    "        # make overlay dicts\n",
    "        _frqd[(tide.replace(' model',''),'Track ' + str(i + 1))] = (dfd * mfd * dmfd).opts(projection=ccrs.PlateCarree(),legend_position='top_left')\n",
    "        _omd[(tide.replace(' model',''),'Track ' + str(i + 1))] = (dnud * mnud * dmnud).opts(projection=ccrs.PlateCarree(),legend_position='top_left')\n",
    "\n",
    "# Make drop down list\n",
    "frqd = hv.HoloMap(_frqd, kdims=['Tide','Track']).opts(infer_projection=True)\n",
    "omd = hv.HoloMap(_omd, kdims=['Tide','Track']).opts(infer_projection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot layout\n",
    "(frqd.opts(width=450) + omd.opts(width=400)).opts(title='Figure 13',shared_axes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descending Track Models: Mean Square Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranges (track x frequency range x wavenumber range)\n",
    "rangesd = np.array([[[.01,.03],[-.008,-.0035]],\n",
    "                  [[.01,.03],[-.008,-.0035]],\n",
    "                  [[0.01,.03,],[-.006,-.003]],\n",
    "                  [[.015,.025],[-.008,-.004]]])\n",
    "\n",
    "# calculate mean square error\n",
    "msed = np.zeros((4,2,2))\n",
    "_ranged = dict()\n",
    "for t_num,t_name in enumerate(tracksd):\n",
    "    \n",
    "    # get ranges\n",
    "    f_range = rangesd[t_num,0,:].tolist()\n",
    "    nu_range = rangesd[t_num,1,:].tolist()\n",
    "    _ranged['Track ' + str(t_num + 1)] = pf.fft_2D_plt(models[t_name]['data'],'').opts(xlim=tuple(nu_range),\n",
    "                                                                                      ylim=tuple(f_range))\n",
    "    # get data spectrum\n",
    "    power_spectrum = models[t_name]['data']\n",
    "    f_vector = power_spectrum['frequencies']\n",
    "    nu_vector = power_spectrum['wavenumbers']\n",
    "    for tide_num, tide in enumerate(['M2 model', 'S2 model']):\n",
    "        \n",
    "        # get model specta\n",
    "        model = models[t_name][tide]['fft 2D']\n",
    "        dmodel = models[t_name]['doppler ' + tide]['fft 2D']\n",
    "        \n",
    "        # solve for mean square error\n",
    "        msed[t_num,tide_num,0] = Jason2.find_square_error(f_range, \n",
    "                                                         nu_range,\n",
    "                                                         f_vector,\n",
    "                                                         nu_vector,\n",
    "                                                         power_spectrum['fft 2D'],\n",
    "                                                         model)\n",
    "        msed[t_num,tide_num,1]= Jason2.find_square_error(f_range,\n",
    "                                                        nu_range,\n",
    "                                                        f_vector,\n",
    "                                                        nu_vector,\n",
    "                                                        power_spectrum['fft 2D'],\n",
    "                                                        dmodel)\n",
    "# output\n",
    "range_pltd = hv.HoloMap(_ranged, kdims='Track').opts(framewise=True,\n",
    "                                                  width=400,height=300)\n",
    "dd = dict()\n",
    "dd['M2'] = pd.DataFrame(columns=['Model', 'Doppler Model',],\n",
    "                                data=msed[:,0,:],\n",
    "                                index = ['Track %.f'%(i+1) for i in range(4)])\n",
    "\n",
    "dd['S2'] = pd.DataFrame(columns=['Model', 'Doppler Model',],\n",
    "                                data=msed[:,1,:],\n",
    "                                index = ['Track %.f'%(i+1) for i in range(4)])\n",
    "\n",
    "pd.set_option('display.float_format', '{:.2E}'.format)\n",
    "dfd = pd.concat(dd, axis=1,names=['Tidal Constituent:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Table 2: Mean Square Error')\n",
    "display(HTML(dfd.to_html()))\n",
    "range_pltd.opts(title='Figure 8: Semi-Diurnal Peaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "(1) https://oceanphysics.files.wordpress.com/2019/08/jpo-d-18-0272.1-1.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
